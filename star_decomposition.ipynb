{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "star_decomposition.ipynb",
      "provenance": [],
      "background_execution": "on",
      "authorship_tag": "ABX9TyM2CZNRzGL3fsrBFfKNtBRb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vfrantc/deweather/blob/main/star_decomposition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-box"
      ],
      "metadata": {
        "id": "5rpOvnrCKLtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import drive\n",
        "drive.mount('drive')"
      ],
      "metadata": {
        "id": "Ekxtl1umLgo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/deweather2/split_star.zip .\n",
        "!unzip split_star.zip"
      ],
      "metadata": {
        "id": "AYGG34MxLnyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from box import Box"
      ],
      "metadata": {
        "id": "knIIsFi-JLR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Box({'epochs': 100,\n",
        "           'batch_size': 16,\n",
        "           'patch_size': 96,\n",
        "           'lr': 0.001})"
      ],
      "metadata": {
        "id": "BQM29xGdJLNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLBoiqBKFsk9"
      },
      "outputs": [],
      "source": [
        "class DecomNet(nn.Module):\n",
        "    def __init__(self, channel=64, kernel_size=3):\n",
        "        super(DecomNet, self).__init__()\n",
        "        # Shallow feature extraction\n",
        "        self.net1_conv0 = nn.Conv2d(6, channel, kernel_size * 3,  padding=4, padding_mode='replicate')\n",
        "        # Activated layers!\n",
        "        self.net1_convs = nn.Sequential(nn.Conv2d(channel, channel, kernel_size, padding=1, padding_mode='replicate'),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Conv2d(channel, channel, kernel_size, padding=1, padding_mode='replicate'),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Conv2d(channel, channel, kernel_size, padding=1, padding_mode='replicate'),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Conv2d(channel, channel, kernel_size, padding=1, padding_mode='replicate'),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Conv2d(channel, channel, kernel_size, padding=1, padding_mode='replicate'),\n",
        "                                        nn.ReLU())\n",
        "        # Final recon layer\n",
        "        self.net1_recon = nn.Conv2d(channel, 6, kernel_size, padding=1, padding_mode='replicate')\n",
        "\n",
        "    def forward(self, input_im):\n",
        "        input_img = torch.cat((input_im, input_im), dim=1)\n",
        "        feats0   = self.net1_conv0(input_img)\n",
        "        featss   = self.net1_convs(feats0)\n",
        "        outs     = self.net1_recon(featss)\n",
        "        R        = torch.sigmoid(outs[:, 0:3, :, :])\n",
        "        L        = torch.sigmoid(outs[:, 3:6, :, :])\n",
        "        return R, L"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = DecomNet()\n",
        "net = net.cuda()\n",
        "lr = opt.lr * np.ones([opt.epochs])\n",
        "lr[20:] = lr[0] / 10.0\n",
        "\n",
        "train_input_data_names = glob('./input/*.png')\n",
        "train_input_data_names.sort()\n",
        "train_slow_data_names = glob('./slow/*.png')\n",
        "train_slow_data_names.sort()\n",
        "train_fast_data_names = glob('./fast/*.png')\n",
        "train_fast_data_names.sort()\n",
        "\n",
        "train_op = optim.Adam(self.net.parameters(), lr=lr[0], betas=(0.9, 0.999))"
      ],
      "metadata": {
        "id": "lO-oW16sTKPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_id   = 0\n",
        "numBatch = len(train_input_data_names) // int(opt.batch_size)\n",
        "start_time = time.time()\n",
        "for epoch in range(0, epoch):\n",
        "    self.lr = lr[epoch]\n",
        "\n",
        "    # Adjust learning rate\n",
        "    for param_group in self.train_op.param_groups:\n",
        "        param_group['lr'] = self.lr\n",
        "\n",
        "    for batch_id in range(0, numBatch):\n",
        "        # Generate training data for a batch\n",
        "        batch_input = np.zeros((opt.batch_size, 3, opt.patch_size, opt.patch_size,), dtype=\"float32\")\n",
        "        batch_slow = np.zeros((opt.batch_size, 3, opt.patch_size, opt.patch_size,), dtype=\"float32\")\n",
        "        batch_fast = np.zeros((opt.batch_size, 3, opt.patch_size, opt.patch_size,), dtype=\"float32\")\n",
        "\n",
        "        for patch_id in range(opt.batch_size):\n",
        "            # Load images\n",
        "            train_input_img = Image.open(train_input_data_names[image_id])\n",
        "            train_input_img = np.array(train_input_img, dtype='float32')/255.0\n",
        "            train_slow_img= Image.open(train_slow_data_names[image_id])\n",
        "            train_slow_img= np.array(train_slow_img, dtype='float32')/255.0\n",
        "            train_fast_img= Image.open(train_fast_data_names[image_id])\n",
        "            train_fast_img= np.array(train_fast_img, dtype='float32')/255.0\n",
        "\n",
        "            # Take random crops\n",
        "            h, w, _        = train_input_img.shape\n",
        "            x = random.randint(0, h - opt.patch_size)\n",
        "            y = random.randint(0, w - opt.patch_size)\n",
        "            train_input_img = train_input_img[x: x + opt.patch_size, y: y + opt.patch_size, :]\n",
        "            train_slow_img= train_slow_img[x: x + opt.patch_size, y: y + opt.patch_size, :]\n",
        "            train_fast_img= train_fast_img[x: x + opt.patch_size, y: y + opt.patch_size, :]\n",
        "\n",
        "            # Data augmentation\n",
        "            if random.random() < 0.5:\n",
        "                train_input_img = np.flipud(train_input_img)\n",
        "                train_slow_img= np.flipud(train_slow_img)\n",
        "                train_fast_img= np.flipud(train_fast_img)\n",
        "            if random.random() < 0.5:\n",
        "                train_input_img = np.fliplr(train_input_img)\n",
        "                train_slow_img= np.fliplr(train_slow_img)\n",
        "                train_fast_img= np.fliplr(train_fast_img)\n",
        "            rot_type = random.randint(1, 4)\n",
        "            if random.random() < 0.5:\n",
        "                train_input_img = np.rot90(train_input_img, rot_type)\n",
        "                train_slow_img= np.rot90(train_slow_img, rot_type)\n",
        "                train_fast_img= np.rot90(train_fast_img, rot_type)\n",
        "            \n",
        "            # Permute the images to tensor format\n",
        "            train_input_img = np.transpose(train_input_img, (2, 0, 1))\n",
        "            train_slow_img= np.transpose(train_slow_img, (2, 0, 1))\n",
        "            train_fast_img= np.transpose(train_fast_img, (2, 0, 1))\n",
        "            \n",
        "            # Prepare the batch\n",
        "            batch_input[patch_id, :, :, :] = train_input_img\n",
        "            batch_slow[patch_id, :, :, :]= train_slow_img\n",
        "            batch_fast[patch_id, :, :, :]= train_fast_img\n",
        "\n",
        "            image_id = (image_id + 1) % len(train_input_data_names)\n",
        "            if image_id == 0:\n",
        "                tmp = list(zip(train_input_data_names, train_slow_data_names, train_fast_data_names))\n",
        "                random.shuffle(list(tmp))\n",
        "                train_input_data_names, train_slow_data_names, train_fast_data_names = zip(*tmp)\n",
        "\n",
        "        input = Variable(torch.FloatTensor(torch.from_numpy(batch_input))).cuda()\n",
        "        target_slow = Variable(torch.FloatTensor(torch.from_numpy(batch_slow))).cuda()\n",
        "        target_fast = Variable(torch.FloatTensor(torch.from_numpy(batch_fast))).cuda()\n",
        "\n",
        "        out_fast, out_slow = net(input)\n",
        "        train_op.zero_grad()\n",
        "        loss = F.l1_loss(out_fast*out_slow,  input)\n",
        "             + F.l1_loss(out_slow, target_slow) \n",
        "             + F.l1_loss(out_fast, target_fast)\n",
        "        loss.backward()\n",
        "        train_op.step()\n",
        "\n",
        "        print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, loss: %.6f\" % (epoch + 1, batch_id + 1, numBatch, time.time() - start_time, loss.item()))\n",
        "        iter_num += 1\n",
        "\n",
        "print(\"Finished training...\")"
      ],
      "metadata": {
        "id": "Rb0rhpGQGVYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P7Hf0o5tGVbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DbWpVjBTGVg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NHE6i3wEGVj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text model"
      ],
      "metadata": {
        "id": "T_dU6ZqHNMsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def save(self, iter_num, ckpt_dir):\n",
        "        save_dir = ckpt_dir + '/' + self.train_phase + '/'\n",
        "        save_name= save_dir + '/' + str(iter_num) + '.tar'\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "        if self.train_phase == 'Decom':\n",
        "            torch.save(self.DecomNet.state_dict(), save_name)\n",
        "        elif self.train_phase == 'Relight':\n",
        "            torch.save(self.RelightNet.state_dict(),save_name)"
      ],
      "metadata": {
        "id": "2jTFMipKGVmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_decom(trainable=True):\n",
        "  net = DecomNet().cuda()\n",
        "  ckpt_dict  = torch.load('ckpts/Decom/9200.tar') # , map_location=torch.device('cpu')\n",
        "  net.load_state_dict(ckpt_dict)\n",
        "  for p in net.parameters():\n",
        "      p.requires_grad = trainable\n",
        "  return net"
      ],
      "metadata": {
        "id": "2D5p0p9kNldu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decom_image(image):\n",
        "  test_low_img   = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "  test_low_img   = np.transpose(test_low_img, (2, 0, 1))\n",
        "  input_low_test = np.expand_dims(test_low_img, axis=0)\n",
        "  input_low_test = Variable(torch.FloatTensor(torch.from_numpy(input_low_test))).cuda()\n",
        "  R_low, I_low   = net(input_low_test)\n",
        "  R_low = np.clip(np.transpose(R_low.cpu().detach().numpy().squeeze(), (1, 2, 0)), 0, 1)\n",
        "  I_low = np.clip(I_low.cpu().detach().numpy().squeeze(), 0, 1)\n",
        "  return R_low, I_low"
      ],
      "metadata": {
        "id": "ZNhRIzavNhdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = get_decom()"
      ],
      "metadata": {
        "id": "OG1RwTrVNiWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/deweather2/input.zip .\n",
        "!unzip input.zip "
      ],
      "metadata": {
        "id": "ooYZO3uLNu3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FNAME = 'input/input/010.png'\n",
        "dehazed_image = cv2.imread(FNAME)\n",
        "reflectance, illumination = decom_image(dehazed_image)\n",
        "\n",
        "fig, axs = plt.subplots(2, figsize=(16, 8))\n",
        "axs[0].imshow(reflectance)\n",
        "axs[1].imshow(illumination, cmap='gray')"
      ],
      "metadata": {
        "id": "I5m0cLpyN_sO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}