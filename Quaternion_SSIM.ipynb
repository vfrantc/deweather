{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vfrantc/deweather/blob/main/Quaternion_SSIM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/Orkis-Research/Pytorch-Quaternion-Neural-Networks.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW-ToD0i2zrX",
        "outputId": "3e1f3257-e6b8-49fe-ba09-08d6dfa9c025"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/Orkis-Research/Pytorch-Quaternion-Neural-Networks.git\n",
            "  Cloning https://github.com/Orkis-Research/Pytorch-Quaternion-Neural-Networks.git to /tmp/pip-req-build-y0v0vzm0\n",
            "  Running command git clone -q https://github.com/Orkis-Research/Pytorch-Quaternion-Neural-Networks.git /tmp/pip-req-build-y0v0vzm0\n",
            "Building wheels for collected packages: Pytorch-QNN\n",
            "  Building wheel for Pytorch-QNN (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Pytorch-QNN: filename=Pytorch_QNN-1-py3-none-any.whl size=21517 sha256=5afb0d42c4ed8523ed27d35adbcd7de9c9885d8afd6eef066ac5eba115ae2733\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h7lcsbpu/wheels/28/96/bc/2d440ce957d6b5ce8d0345b758b7828d07fae2c5a9f3fae8c7\n",
            "Successfully built Pytorch-QNN\n",
            "Installing collected packages: Pytorch-QNN\n",
            "Successfully installed Pytorch-QNN-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import math\n",
        "import numpy as np\n",
        "from math import exp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from core_qnn.quaternion_ops import q_normalize\n",
        "from core_qnn.quaternion_ops import get_r\n",
        "from core_qnn.quaternion_ops import get_i \n",
        "from core_qnn.quaternion_ops import get_j \n",
        "from core_qnn.quaternion_ops import get_k \n",
        "from core_qnn.quaternion_ops import get_modulus\n",
        "from core_qnn.quaternion_ops import get_normalized\n",
        "from core_qnn.quaternion_ops import quaternion_conv\n",
        "from core_qnn.quaternion_ops import hamilton_product\n",
        "\n",
        "def q_conj(input, channel=1):\n",
        "    r = get_r(input)\n",
        "    i = -get_i(input)\n",
        "    j = -get_j(input)\n",
        "    k = -get_k(input)\n",
        "    return torch.cat([r,i,j,k], dim=channel)\n",
        "\n",
        "def img_to_q(input, channel=1):\n",
        "    b, c, h, w = input.size()\n",
        "    real = torch.zeros((b, 1, h, w))\n",
        "    if input.is_cuda:\n",
        "        real = real.cuda(real.get_device())\n",
        "    x = torch.cat([real, input], dim=channel)\n",
        "    return x\n",
        "\n",
        "def get_L(input, channel=1):\n",
        "    red, green, blue = torch.split(input, 1, dim=1)\n",
        "    L = red/3 + green/3 + blue/3\n",
        "    luminance = torch.cat([L, L, L], dim=1)\n",
        "    return luminance"
      ],
      "metadata": {
        "id": "qgPiHPvtKHco"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "!cp -r /content/drive/MyDrive/qssim . "
      ],
      "metadata": {
        "id": "tYZ97T2TslWw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3327882a-1af3-45c3-aad9-5e63af1d7590"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n",
        "    return gauss / gauss.sum()"
      ],
      "metadata": {
        "id": "Y1ymYNHkCnAk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_window(window_size, channel):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
        "    return window"
      ],
      "metadata": {
        "id": "lT7PDRigKA70"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _ssim(img1, img2, window_size, size_average=True):\n",
        "    L = 1\n",
        "    ch = 1\n",
        "\n",
        "    window3 = create_window(window_size, channel=3)\n",
        "    if img1.is_cuda:\n",
        "        window3 = window3.cuda(img1.get_device())\n",
        "    window3 = window3.type_as(img1)\n",
        "\n",
        "    window4 = create_window(window_size, channel=4)\n",
        "    if img1.is_cuda:\n",
        "        window4 = window4.cuda(img1.get_device())\n",
        "    window4 = window4.type_as(img1)\n",
        "\n",
        "    # for ch=1 it does nothing\n",
        "    img1_L = get_L(img1)\n",
        "    img1_ch = img1-img1_L\n",
        "    img1 = img1_ch*ch + img1_L\n",
        "\n",
        "    img2_L = get_L(img2)\n",
        "    img2_ch = img2 - img2_L\n",
        "    img2 = img2_ch*ch + img2_L\n",
        "\n",
        "    img1_Q = img_to_q(img1)\n",
        "    img2_Q = img_to_q(img2)\n",
        "\n",
        "    C1 = torch.tensor([[[[0.01**2]], [[0.]], [[0.]], [[0.]]]])\n",
        "    C2 = torch.tensor([[[[0.03**2]], [[0.]], [[0.]], [[0.]]]])\n",
        "\n",
        "    mu1 = F.conv2d(img1, window3, padding=window_size // 2, groups=3)\n",
        "    mu2 = F.conv2d(img2, window3, padding=window_size // 2, groups=3)\n",
        "    mu1_Q = img_to_q(mu1)\n",
        "    mu2_Q = img_to_q(mu2)\n",
        "    mu1_sq_Q = hamilton_product(mu1_Q, q_conj(mu1_Q))\n",
        "    mu2_sq_Q = hamilton_product(mu2_Q, q_conj(mu2_Q))\n",
        "    mu1_mu2_Q = hamilton_product(mu1_Q, q_conj(mu2_Q))\n",
        "\n",
        "    img1_hue_sq_Q = hamilton_product(img1_Q, q_conj(img1_Q))\n",
        "    img2_hue_sq_Q = hamilton_product(img2_Q, q_conj(img2_Q))\n",
        "    img1_img2_hue_Q = hamilton_product(img1_Q, q_conj(img2_Q))\n",
        "\n",
        "    sigma1_sq_Q = F.conv2d(img1_hue_sq_Q, window4, padding=window_size // 2, groups=4) - mu1_sq_Q\n",
        "    sigma2_sq_Q = F.conv2d(img2_hue_sq_Q, window4, padding=window_size // 2, groups=4) - mu2_sq_Q\n",
        "    sigma12_Q = F.conv2d(img1_img2_hue_Q, window4, padding=window_size // 2, groups=4) - mu1_mu2_Q\n",
        "    \n",
        "    # ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
        "    #  numerator1 = 2*mu1_mu2 + C1;\n",
        "    #  numerator2 = 2*sigma12 + C2;\n",
        "    # denominator1 = mu1_sq + mu2_sq + C1;\n",
        "    #  denominator2 = sigma1_sq + sigma2_sq + C2;\n",
        "    #  qssim_map = ones(size(mu1));\n",
        "    #  index = (denominator1.*denominator2 > 0);\n",
        "    #  qssim_map(index) = (numerator1(index).*numerator2(index))./(denominator1(index).*denominator2(index));\n",
        "    #  index = (denominator1 ~= 0) & (denominator2 == 0);\n",
        "    #  qssim_map(index) = numerator1(index)./denominator1(index);\n",
        "\n",
        "\n",
        "    qssim_map_Q = ((2*mu1_mu2_Q + C1) * (2*q_conj(sigma12_Q) + C2)) #/ ((mu1_sq_Q + mu2_sq_Q + C1) * (q_conj(sigma1_sq_Q + sigma2_sq_Q) + C2))\n",
        "    ssim_map = get_modulus(qssim_map_Q)\n",
        "\n",
        "    if size_average:\n",
        "        return ssim_map.mean()\n",
        "    else:\n",
        "        return ssim_map.mean(1).mean(1).mean(1)"
      ],
      "metadata": {
        "id": "9e8XsljZCm54"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ssim(img1, img2, window_size=11, size_average=True):\n",
        "    img1=torch.clamp(img1,min=0,max=1)\n",
        "    img2=torch.clamp(img2,min=0,max=1)\n",
        "    (_, channel, _, _) = img1.size()\n",
        "    window = create_window(window_size, channel)\n",
        "    if img1.is_cuda:\n",
        "        window = window.cuda(img1.get_device())\n",
        "    window = window.type_as(img1)\n",
        "    return _ssim(img1, img2, window_size, size_average)"
      ],
      "metadata": {
        "id": "0K47sZVZCm3F"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_ssim(img1_name, img2_name, cuda=False):\n",
        "  img1 = cv2.imread(img1_name, 1)\n",
        "  img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "  img1 = np.transpose(img1, (2, 0, 1))\n",
        "  img1 = np.expand_dims(img1, axis=0)\n",
        "  img1 = Variable(torch.FloatTensor(torch.from_numpy(img1)))\n",
        "  if cuda:\n",
        "    img1 = img1.cuda()\n",
        "  \n",
        "  img2 = cv2.imread(img2_name, 1)\n",
        "  img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "  img2 = np.transpose(img2, (2, 0, 1))\n",
        "  img2 = np.expand_dims(img2, axis=0)\n",
        "  img2 = Variable(torch.FloatTensor(torch.from_numpy(img2)))\n",
        "  if cuda:\n",
        "    img2 = img2.cuda()\n",
        "  return ssim(img1, img2)"
      ],
      "metadata": {
        "id": "KhyTtfV3Cm0l"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF99CSQX0H23",
        "outputId": "c9e5f35b-4f36-4b52-e23f-b9c20fdb53b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0102)\n"
          ]
        }
      ],
      "source": [
        "print(run_ssim('qssim/image1.jpg', 'qssim/image2.jpg'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img1 = cv2.imread('qssim/image1.jpg', 1)\n",
        "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "img1 = np.transpose(img1, (2, 0, 1))\n",
        "img1 = np.expand_dims(img1, axis=0)\n",
        "img1 = Variable(torch.FloatTensor(torch.from_numpy(img1)))"
      ],
      "metadata": {
        "id": "FEL3x-fxPXjx"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img1.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR3HgBP-FQJ4",
        "outputId": "f05026e0-07ff-44f5-b738-c1fe012dacef"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 391, 660])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "red, green, blue = torch.split(img1, 1, dim=1)"
      ],
      "metadata": {
        "id": "FLyBeEiAF-0N"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "red.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piQ7tuGlGHSk",
        "outputId": "41328272-ec7e-4bad-b487-a865139a7fb7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 391, 660])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sOsqvOXLGJF9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Quaternion SSIM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN5vdEKsVTWjPl0KJOtjyHC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}